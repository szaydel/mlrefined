{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.5 Dials and knobs of neural network bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biological neuron is just a single cell, of which there are roughly $10^{11}$ inside the human brain. Thus to perform any cognitive task, we need a sizable series of interconnected neurons - also known as a *neural network* - to interact. For example somewhere between $10^{5}$ to $10^{6}$ neurons are required to render a realistic image of our visual surroundings [[4]](#bib_cell).  \n",
    " \n",
    "Motivated by biological neural networks, artificial neural networks are created by arranging artificial neurons in a series of *layers*. Figure 4 illustrates a neural network with two layers, each consisting of $9$ and $11$ artificial neurons or *units*, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"../../mlrefined_images/nonlinear_superlearn_images/2_layer_neural_network.png\" width=\"80%\" height=\"auto\"/>\n",
    "<figcaption> <strong>Figure 4:</strong> <em> A fully-connected feed-forward artificial neural network with two hidden layers. </em>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network shown in Figure 4 is referred to, more verbosely, as a fully-connected feed-forward artificial neural network with two hidden layers: *fully-connected* because each neuron is connected to all neurons in the previous and next layers, and *feed-forward* because the flow of information is always in the forward direction, from the inputs on the left to the output on the right. Because an outside viewer supposedly only sees these inputs and output, the in-between layers are sometimes called *hidden* layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.3 Biological plausibility: a blessing or a curse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our understanding of the neurophysiology of the brain can help us choose a mathematical form for the activation function $a\\left(\\cdot\\right)$. As discussed in the previous Subsection, a neuron fires only when its input exceeds a certain threshold. This motivated the use of a 0/1 step as activation function in the original perceptron model [[3]](#bib_cell). While biologically plausible, a discontinuous step function introduces serious issues with respect to tuning neural network weights as it rules out the use of gradient-based optimization methods. Three decades later researchers ameliorated this issue by dropping the step function in favor of its smooth approximator: the logistic sigmoid function. However it turns out the sigmoid function too suffers from an optimization-related flaw: the gradient of the sigmoid function is effectively zero outside a relatively small region near the origin. With the recent resurgence of neural networks as deep learning and use of new activation functions such as ReLU, the trend in the machine learning community to sacrifice biological plausibility to gain better optimization - and consequently better accuracy - has continued.\n",
    "\n",
    "In conclusion, artificial neural networks having been introduced originally as a mathematical model for the interconnection of biological neurons inside the brain, are being employed in machine learning today, first and foremost, as function approximators.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bib_cell'></a>\n",
    "\n",
    "## References\n",
    "\n",
    "[1]  W. S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4):115–133, 1943.\n",
    "\n",
    "[2]  D. O. Hebb. The organization of behavior: a neuropsychological theory. John Wiley & Sons, New York, 1949.\n",
    "\n",
    "[3]  F. Rosenblatt. The perceptron - a perceiving and recognizing automaton. Cornell Aeronautical Laboratory, 1957.\n",
    "\n",
    "[4]  B. Merker. From probabilities to percepts: a subcortical \"global best estimate buffer\" as locus of phenomenal experience\". In: S. Edelman, T. Fekete and N. Zach (Eds.) Being in time: Dynamical models of phenomenal experience. (pp. 37–79). John Benjamins Publishing Company, Amsterdam, 2012."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "214px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
